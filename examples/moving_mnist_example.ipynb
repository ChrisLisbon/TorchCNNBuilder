{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Example of using TorchCNNBuilder for MovingMnist dataset",
   "id": "8e09a7e1f229bd59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### MovingMnist dataset is benchmark for video forecasting task. It is presented by 1000 samples with 20 frames series with numbers which are moving on different trajectories. It can be loaded by [official link](https://www.cs.toronto.edu/~nitish/unsupervised_video/).",
   "id": "3f77501b70f4d95b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T09:56:21.168973Z",
     "start_time": "2024-10-14T09:56:16.776957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn, optim, tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchcnnbuilder.models import ForecasterBase\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ],
   "id": "31ed0de82a611c0e",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Data preparation include normalization and separating on train and test parts. As features (input) for model first 17 frames are used, as target (output) last 3 frames are used.\n",
    "\n",
    "It should be noticed, that there is **not cyclic component** in each time-spatial series. So model should learn dynamics of numbers moving by examples from other series (on other numbers). And convolutional layers should help to reproduce view of number by previous frames of series. "
   ],
   "id": "870f9fb24b72dcf2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T09:56:23.661012Z",
     "start_time": "2024-10-14T09:56:21.169973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = np.load('data/moving_mnist.npy').astype(np.float32)/255\n",
    "\n",
    "train_set = data[:, :8000, :, :]\n",
    "test_set = data[:, 8000:, :, :]\n",
    "\n",
    "train_features = train_set[:17, :, :, :]\n",
    "train_features = np.swapaxes(train_features, 0, 1)\n",
    "train_target = train_set[17:, :, :, :]\n",
    "train_target = np.swapaxes(train_target, 0, 1)\n",
    "\n",
    "train_dataset = TensorDataset(tensor(train_features), tensor(train_target))"
   ],
   "id": "952753315f5e41c9",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Model building with simple structure - 5 convolutional and 5 transposed convolutional layers. Resolution of images is 64x64 pixels and also specified",
   "id": "b86aa925b8125910"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T09:56:23.898013Z",
     "start_time": "2024-10-14T09:56:23.662013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Calculation on device: {device}')\n",
    "model = ForecasterBase(input_size=[64, 64],\n",
    "                       in_time_points=17,\n",
    "                       out_time_points=3,\n",
    "                       n_layers=5)\n",
    "model = model.to(device)"
   ],
   "id": "28b3c7ce2bf1a6f6",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Set parameters for training. The simple strategy without scheduler is presented. Epochs number and batch size can be changed depend on device and quality requirements.",
   "id": "da00804a44727815"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T09:56:24.859588Z",
     "start_time": "2024-10-14T09:56:23.899012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 2000\n",
    "batch_size = 100\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()"
   ],
   "id": "865f21b5b683f464",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Model training on 8000 samples. Loss values per epoch are saved for convergence visualization  \n",
   "id": "182baa2786178d7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T11:20:10.342587Z",
     "start_time": "2024-10-14T09:56:24.861554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "progress_bar = tqdm(list(np.arange(epochs)), desc=\"Epoch\", colour=\"white\")\n",
    "info_bar = {\"Loss\": 0}\n",
    "losses = []\n",
    "epoches = []\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for train_features, train_targets in dataloader:\n",
    "        train_features = train_features.to(device)\n",
    "        train_targets = train_targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_features)\n",
    "\n",
    "        train_loss = criterion(outputs, train_targets)\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    loss = loss / len(dataloader)\n",
    "    \n",
    "    info_bar['Loss'] = np.round(loss, 5)\n",
    "    progress_bar.update()\n",
    "    progress_bar.set_postfix_str(info_bar)\n",
    "\n",
    "    losses.append(loss)\n",
    "    epoches.append(epoch)\n",
    "\n",
    "torch.save(model.state_dict(), f'mnist_{epochs}.pt')"
   ],
   "id": "aeddbfcb6a8d497c",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Loss value per epoch visualization. A gradual decrease in loss values indicates that the task has been set correctly.",
   "id": "ebfceeb3bbc01a22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T11:20:10.517588Z",
     "start_time": "2024-10-14T11:20:10.343587Z"
    }
   },
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "plt.plot(epoches, losses)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('L1 Loss')\n",
    "plt.title('Convergence plot')\n",
    "plt.show()"
   ],
   "id": "158e21693348b808",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Quality estimation on test set\n",
    "##### *Loading features and target for test set* "
   ],
   "id": "ca60eb366949f460"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T11:59:32.768505Z",
     "start_time": "2024-10-14T11:59:32.761515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_features = test_set[:17, :, :, :]\n",
    "test_features = np.swapaxes(test_features, 0, 1)\n",
    "test_target = test_set[17:, :, :, :]\n",
    "test_target = np.swapaxes(test_target, 0, 1)\n",
    "print('Data loaded')"
   ],
   "id": "7d5acbcc242f9257",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### *MAE (mean absolute error) calculation for each sample of test set*",
   "id": "662357d6cbb46937"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T12:22:38.919526Z",
     "start_time": "2024-10-14T12:22:35.939867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l1_errors = []\n",
    "for s in range(test_features.shape[0]):\n",
    "    features = tensor(test_features[s]).to(device)\n",
    "    prediction = model(features).detach().cpu().numpy()\n",
    "    target = test_target[s]\n",
    "    mae = np.mean(abs(prediction - target))\n",
    "    l1_errors.append(mae)\n",
    "print(f'Mean MAE for test set = {np.mean(l1_errors)}')  "
   ],
   "id": "7ea14812103a9542",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Visualization of prediction results on test set (for first 5 samples) ",
   "id": "12a6f9343bf2f598"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T12:23:16.961107Z",
     "start_time": "2024-10-14T12:23:15.561655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for s in range(5):\n",
    "    tensor_features = tensor(test_features[s]).to(device)\n",
    "    prediction = model(tensor_features).detach().cpu().numpy()\n",
    "    plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "    fig, axs = plt.subplots(2, 3)\n",
    "    for i in range(3):\n",
    "        axs[0][i].imshow(prediction[i])\n",
    "        axs[1][i].imshow(test_target[s][i])\n",
    "    plt.suptitle(f'Sample {s}')\n",
    "    plt.show()"
   ],
   "id": "e18517cdad9b8f27",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It can be concluded that the predictive ability of such a model with described training scheme is limited to 2 frames, despite the high quality metric. ",
   "id": "64b8a033b4409509"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
