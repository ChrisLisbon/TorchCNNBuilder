{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## This example show the ability of CNN with encoder-decoder architecture to approximate complex media data with periodic component.  ",
   "id": "89c6d2f14020350f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### As data source gif-file with Menhera manga character was used. Gif-file contains 10 frames (3 channel RGB images). Resolution of images was reduced to 45x45 pixels to light the task.",
   "id": "b816f50889ff4fb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![SegmentLocal](tools/media/anime_10f_fullsize.gif \"segment\")",
   "id": "7778517c8d6a362e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Function to prepare dataset from gif-file to numpy matrices  ",
   "id": "cff823cde99499ca"
  },
  {
   "cell_type": "code",
   "id": "e6a3d5d05db5d1ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T13:47:26.773281Z",
     "start_time": "2024-10-14T13:47:26.371090Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageSequence\n",
    "\n",
    "def get_anime_timeseries(rgb=True):\n",
    "    with Image.open('tools/media/anime_10f.gif') as im:\n",
    "        array = []\n",
    "        for frame in ImageSequence.Iterator(im):\n",
    "            if rgb:\n",
    "                im_data = frame.copy().convert('RGB').getdata()\n",
    "                im_array = np.array(im_data).reshape(frame.size[1], frame.size[0], 3)\n",
    "            else:\n",
    "                im_data = frame.copy().convert('L').getdata()\n",
    "                im_array = np.array(im_data).reshape(frame.size[1], frame.size[0], 1)\n",
    "            array.append(im_array)\n",
    "        array = np.array(array)        \n",
    "        array = array/255\n",
    "    return array\n",
    "\n",
    "\n",
    "def get_cycled_data(cycles_num, is_rgb):\n",
    "    array = get_anime_timeseries(rgb=is_rgb)\n",
    "    arr = []\n",
    "    for i in range(cycles_num):\n",
    "        arr.append(array)\n",
    "    arr = np.array(arr)\n",
    "    arr = arr.reshape(arr.shape[0]*arr.shape[1], arr.shape[2], arr.shape[3], arr.shape[4])\n",
    "    return arr"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train / test set initialization",
   "id": "358b31f37a88b22"
  },
  {
   "cell_type": "code",
   "id": "61165453374fda73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T13:47:27.408795Z",
     "start_time": "2024-10-14T13:47:26.774283Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = get_cycled_data(5, is_rgb=False)[:, :, :, 0]\n",
    "print(f'Train shape: {train.shape}')\n",
    "test = get_cycled_data(1, is_rgb=False)[:, :, :, 0]\n",
    "print(f'Test shape: {test.shape}')\n",
    "\n",
    "\n",
    "plt.imshow(train[3], cmap='Greys_r')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preparation datasets with moving window depend on prehistory and forecast horizon",
   "id": "364fb9afaecefeb1"
  },
  {
   "cell_type": "code",
   "id": "4fdf405ba3465604",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T13:47:37.510282Z",
     "start_time": "2024-10-14T13:47:34.330504Z"
    }
   },
   "source": [
    "from torchcnnbuilder.preprocess._dynamic_window import multi_output_tensor, single_output_tensor\n",
    "\n",
    "train_dataset = multi_output_tensor(data=train,\n",
    "                                    pre_history_len=20,\n",
    "                                    forecast_len=10)\n",
    "test_dataset = single_output_tensor(data=test, \n",
    "                                   forecast_len=10)"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Simple model (with 5 layers of convolutions and 5 layers of transpose convolutions) initialization - 20 frames as prehistory, 10 frames as forecast horizon.",
   "id": "e94944db3d96a166"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T13:51:57.747851Z",
     "start_time": "2024-10-14T13:51:57.547895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from torchcnnbuilder.models import ForecasterBase\n",
    "\n",
    "model = ForecasterBase(input_size=[45, 45],\n",
    "                       in_time_points=20,\n",
    "                       out_time_points=10,\n",
    "                       n_layers=5,\n",
    "                       finish_activation_function=nn.ReLU(inplace=True))\n",
    "device='cuda'\n",
    "model=model.to(device)"
   ],
   "id": "bcea5d367faf7a3e",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train parameters set ",
   "id": "81a0c18bb9762c6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:13:30.181383Z",
     "start_time": "2024-10-14T14:13:29.281678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "epochs = 100000\n",
    "batch_size = 500\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.L1Loss()\n",
    "losses = []\n",
    "epochs_list = []"
   ],
   "id": "5bb4b425f1a33233",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training the model with progress save ",
   "id": "9328de589692b60d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:25:59.822849Z",
     "start_time": "2024-10-14T14:19:12.883444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# create folder for predicted images save\n",
    "root = os.path.abspath(\"\")\n",
    "opt_hist_path = f'{root}/anime_opt_hist_images'\n",
    "if not os.path.exists(opt_hist_path):\n",
    "    os.makedirs(opt_hist_path)\n",
    "\n",
    "start = time.time()\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    loss = 0\n",
    "    \n",
    "    for train_features, test_features in dataloader:\n",
    "        train_features = train_features.to(device)\n",
    "        test_features = test_features.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_features)    \n",
    "        train_loss = criterion(outputs, test_features)        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()        \n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    loss = loss / len(dataloader)    \n",
    "    losses.append(loss)\n",
    "    epochs_list.append(epoch)\n",
    "    \n",
    "    # here we save optimization history as predicted images to visualize convergence process\n",
    "    if epoch % 10000 == 0 or epoch == 5 or epoch==50 or epoch==300 or epoch == 1000 or epoch == 5000:\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            prediction = model(X)\n",
    "            prediction = prediction.detach().cpu().numpy()[0]\n",
    "            real = y.numpy()[0]\n",
    "    \n",
    "            fig, (axs) = plt.subplots(2, 10, figsize=(10, 3))\n",
    "            for i in range(10):\n",
    "                axs[1, i].imshow(prediction[i], cmap='Greys_r', vmax=1, vmin=0)\n",
    "                axs[1, i].set_title(F'Frame {i}')\n",
    "                axs[0, i].imshow(real[i], cmap='Greys_r', vmax=1, vmin=0)\n",
    "                axs[0, i].set_title(F'Frame {i}')\n",
    "                axs[0, i].set_xticks([])\n",
    "                axs[1, i].set_xticks([])\n",
    "                axs[0, i].set_yticks([])\n",
    "                axs[1, i].set_yticks([])\n",
    "            plt.suptitle(f'Epoch={epoch}, loss={round(loss, 3)}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{opt_hist_path}/test_images_{epoch}.png')\n",
    "            plt.close()\n",
    "\n",
    "end = time.time()\n",
    "print(f'time spent: {end-start}')"
   ],
   "id": "1075054a695b6ee0",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now in folder ***anime_opt_hist_images*** we have visualization of convergence process.  Saved png processed to gif: ",
   "id": "be7ac8e76e885ad1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![SegmentLocal](tools/media/anime_convergence.gif \"segment\")",
   "id": "c81ce9fcba439e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Lets visualize convergence plot",
   "id": "587e7a185a3cf2f8"
  },
  {
   "cell_type": "code",
   "id": "9f589401e37f5182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:34:28.896386Z",
     "start_time": "2024-10-14T14:34:28.798344Z"
    }
   },
   "source": [
    "plt.plot(epochs_list, losses)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('L1 Loss')\n",
    "plt.title('Loss history')\n",
    "plt.show()"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Conclusion",
   "id": "6c93dd802f1f3600"
  },
  {
   "cell_type": "code",
   "id": "8b2b11a97ed71d17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:37:05.521583Z",
     "start_time": "2024-10-14T14:37:05.516581Z"
    }
   },
   "source": [
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters of the model: {params}')"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this case media data can be determined as synthetic time series with periodic component. As we can see from convergence plot and prediction visualizations during training, such simple model (less than 100k parameters) has ability to correctly approximate complex synthetic data.   ",
   "id": "59d13d619d31c55e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
