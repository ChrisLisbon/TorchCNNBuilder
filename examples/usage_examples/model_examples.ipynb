{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:38:10.349669Z",
     "start_time": "2024-06-27T18:38:10.343595Z"
    }
   },
   "source": [
    "# set up an absolute path to the project \n",
    "# not needed in case of `pip install`\n",
    "%run -i tools/setup_env.py"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage examples of `torchcnnbuilder.models`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submodule contains CNN-model templates that were assembled using `torchcnnbuilder.builder`. So far, there is only a model template for predicting n-dimensional time series *(two-dimensional convolutional layers are used)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model `ForecasterBase`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization params:\n",
    "* **input_size** (Tuple[int, int]): input size of the input tensor of the one time point\n",
    "* **n_layers** (int): number of the convolution layers in the encoder part\n",
    "* **in_time_points** (int): number of time points (channels) in the first input tensor (prehistory size)\n",
    "* **out_time_points** number of time points (channels) in the last output tensor (forecasting size)\n",
    "* **conv_dim**: the dimension of the convolutional operation 2 or 3. Default: 2\n",
    "* **n_transpose_layers** (Optional[int]): number of the transpose convolution layers in the encoder part. Default: None (same as n_layers)\n",
    "* **convolve_params** (Dict[str, int]): parameters of convolutional layers (by default same as in torch). Default: None\n",
    "* **transpose_convolve_params** (Dict[str, int]): parameters of transpose convolutional layers (by default same as in torch). Default: None\n",
    "* **activation_function** (nn.Module): activation function. Default: nn.ReLU(inplace=True)\n",
    "* **finish_activation_function** (Union[str, Optional[nn.Module]]): last activation function, can be same as activation_function (str `'same'`). Default: None\n",
    "* **normalization** (str): choice of normalization between str `'dropout'` and `'batchnorm'`. Default: None\n",
    "\n",
    "Other attributes:\n",
    "* **convolve** (nn.Sequential): convolutional sequence - encoder part\n",
    "* **transpose** (nn.Sequential): transpose convolutional sequence - decoder part\n",
    "* **conv_channels** (List[int]): history list of output channels after each convolutional layer\n",
    "* **transpose_conv_channels** (List[int]): history list of output channels after each transposed convolutional layer\n",
    "* **conv_layers** (List[tuple]): history list of output tensor sizes after each convolutional layer\n",
    "* **transpose_conv_layers** (List[tuple]): history list of output tensor sizes after each transposed convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the template class of the time series prediction CNN-architecture. The source of the original [article code](https://github.com/ITMO-NSS-team/ice-concentration-prediction-paper?ysclid=lrhxbvsk8s328492826). Below is a diagram of the original architecture of the model (2D version)\n",
    "\n",
    "<img src=\"./tools/media/ForecasterBase.png\" alt=\"forecaster model\" style=\"width:70%; display: block; margin-left: auto; margin-right: auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T18:18:39.235640Z",
     "iopub.status.busy": "2024-01-25T18:18:39.234694Z",
     "iopub.status.idle": "2024-01-25T18:18:42.600887Z",
     "shell.execute_reply": "2024-01-25T18:18:42.600101Z",
     "shell.execute_reply.started": "2024-01-25T18:18:39.235602Z"
    },
    "ExecuteTime": {
     "end_time": "2024-07-13T06:52:24.694379Z",
     "start_time": "2024-07-13T06:52:23.888551Z"
    }
   },
   "source": [
    "from torchcnnbuilder.models import ForecasterBase"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T18:18:42.602812Z",
     "iopub.status.busy": "2024-01-25T18:18:42.602398Z",
     "iopub.status.idle": "2024-01-25T18:18:42.667243Z",
     "shell.execute_reply": "2024-01-25T18:18:42.666551Z",
     "shell.execute_reply.started": "2024-01-25T18:18:42.602785Z"
    },
    "ExecuteTime": {
     "end_time": "2024-07-13T06:52:33.333390Z",
     "start_time": "2024-07-13T06:52:33.318811Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# example of initialization\n",
    "model = ForecasterBase(input_size=[65, 65],\n",
    "                       in_time_points=120,\n",
    "                       out_time_points=40,\n",
    "                       n_layers=5,\n",
    "                       normalization='batchnorm',\n",
    "                       finish_activation_function=nn.ReLU(inplace=True))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model on the synthetic data that was demonstrated in the `prerocess_examples.ipynb` file. First, we will generate the necessary data and create datasets for the train and test parts. We will predict 40 frames of the square movement based on the previous 120 frames and will use batch normalization. A frame-by-frame animation of the train part is attached below:\n",
    "\n",
    "<img src=\"./tools/media/train.gif\" alt=\"animation\" style=\"width:40%; display: block; margin-left: auto; margin-right: auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T18:18:42.685262Z",
     "iopub.status.busy": "2024-01-25T18:18:42.684978Z",
     "iopub.status.idle": "2024-01-25T18:18:42.776584Z",
     "shell.execute_reply": "2024-01-25T18:18:42.775749Z",
     "shell.execute_reply.started": "2024-01-25T18:18:42.685238Z"
    },
    "ExecuteTime": {
     "end_time": "2024-07-13T06:35:55.750781Z",
     "start_time": "2024-07-13T06:35:55.161216Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# using ssim as loss and score metric (firstly you need to pip install it)\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "# time-series preprocessing\n",
    "from torchcnnbuilder.preprocess.time_series import multi_output_tensor, single_output_tensor\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T18:18:42.778004Z",
     "iopub.status.busy": "2024-01-25T18:18:42.777664Z",
     "iopub.status.idle": "2024-01-25T18:18:43.018338Z",
     "shell.execute_reply": "2024-01-25T18:18:43.017463Z",
     "shell.execute_reply.started": "2024-01-25T18:18:42.777973Z"
    },
    "ExecuteTime": {
     "end_time": "2024-07-13T06:35:56.651775Z",
     "start_time": "2024-07-13T06:35:56.582592Z"
    }
   },
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "print(f'Calculating on device: {device}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%%capture\n",
    "from tools.generating_time_series import synthetic_time_series"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T18:18:43.077882Z",
     "iopub.status.busy": "2024-01-25T18:18:43.077309Z",
     "iopub.status.idle": "2024-01-25T18:18:47.630327Z",
     "shell.execute_reply": "2024-01-25T18:18:47.629371Z",
     "shell.execute_reply.started": "2024-01-25T18:18:43.077852Z"
    }
   },
   "source": [
    "%%capture\n",
    "# generating data\n",
    "_, data = synthetic_time_series(num_frames=360,\n",
    "                                matrix_size=65,\n",
    "                                square_size=13)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T18:18:47.632216Z",
     "iopub.status.busy": "2024-01-25T18:18:47.631955Z",
     "iopub.status.idle": "2024-01-25T18:18:47.636452Z",
     "shell.execute_reply": "2024-01-25T18:18:47.635588Z",
     "shell.execute_reply.started": "2024-01-25T18:18:47.632194Z"
    }
   },
   "source": [
    "# train consists of three cycles of a full circle of the square so that the model can see the trend\n",
    "train = data + data + data\n",
    "test = data[10:170]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T18:18:47.637856Z",
     "iopub.status.busy": "2024-01-25T18:18:47.637563Z",
     "iopub.status.idle": "2024-01-25T18:18:47.648489Z",
     "shell.execute_reply": "2024-01-25T18:18:47.647746Z",
     "shell.execute_reply.started": "2024-01-25T18:18:47.637832Z"
    }
   },
   "source": [
    "print(f'Train dataset len: {len(train)}, One matrix shape: {train[0].shape}')\n",
    "print(f'Test dataset len: {len(test)}, One matrix shape: {test[0].shape}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T18:18:47.651083Z",
     "iopub.status.busy": "2024-01-25T18:18:47.650649Z",
     "iopub.status.idle": "2024-01-25T18:18:49.789509Z",
     "shell.execute_reply": "2024-01-25T18:18:49.788528Z",
     "shell.execute_reply.started": "2024-01-25T18:18:47.651052Z"
    }
   },
   "source": [
    "train_dataset = multi_output_tensor(data=train,\n",
    "                                    pre_history_len=120,\n",
    "                                    forecast_len=40)\n",
    "\n",
    "test_dataset = single_output_tensor(data=test, \n",
    "                                   forecast_len=40)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T18:18:49.790939Z",
     "iopub.status.busy": "2024-01-25T18:18:49.790630Z",
     "iopub.status.idle": "2024-01-25T18:18:49.799103Z",
     "shell.execute_reply": "2024-01-25T18:18:49.798206Z",
     "shell.execute_reply.started": "2024-01-25T18:18:49.790914Z"
    }
   },
   "source": [
    "# checking train_dataset\n",
    "for i, batch in enumerate(train_dataset):\n",
    "    print(f'batch number: {i}',\n",
    "          f'X shape: {batch[0].shape}\\nY shape: {batch[1].shape}',\n",
    "          sep='\\n',\n",
    "          end='\\n\\n')\n",
    "    break\n",
    "print(f'Dataset len (number of batches/X-windows): {len(train_dataset)}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T18:18:49.800594Z",
     "iopub.status.busy": "2024-01-25T18:18:49.800274Z",
     "iopub.status.idle": "2024-01-25T18:18:49.821674Z",
     "shell.execute_reply": "2024-01-25T18:18:49.820798Z",
     "shell.execute_reply.started": "2024-01-25T18:18:49.800564Z"
    }
   },
   "source": [
    "# checking test_dataset\n",
    "for i, batch in enumerate(test_dataset):\n",
    "    print(f'X shape: {batch[0].shape}\\nY shape: {batch[1].shape}',\n",
    "          end='\\n\\n')\n",
    "\n",
    "print(f'Dataset len (number of batches/X-windows): {len(test_dataset)}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T18:18:49.822940Z",
     "iopub.status.busy": "2024-01-25T18:18:49.822646Z",
     "iopub.status.idle": "2024-01-25T18:18:49.832032Z",
     "shell.execute_reply": "2024-01-25T18:18:49.831180Z",
     "shell.execute_reply.started": "2024-01-25T18:18:49.822918Z"
    }
   },
   "source": [
    "epochs = 1000\n",
    "batch_size = 50\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T18:18:49.833885Z",
     "iopub.status.busy": "2024-01-25T18:18:49.833209Z",
     "iopub.status.idle": "2024-01-25T18:18:49.843440Z",
     "shell.execute_reply": "2024-01-25T18:18:49.842692Z",
     "shell.execute_reply.started": "2024-01-25T18:18:49.833860Z"
    }
   },
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.L1Loss()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T18:19:00.382605Z",
     "iopub.status.busy": "2024-01-25T18:19:00.381868Z",
     "iopub.status.idle": "2024-01-25T20:25:36.410329Z",
     "shell.execute_reply": "2024-01-25T20:25:36.409349Z",
     "shell.execute_reply.started": "2024-01-25T18:19:00.382574Z"
    }
   },
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    loss = 0\n",
    "    \n",
    "    for train_features, test_features in dataloader:\n",
    "        train_features = train_features.to(device)\n",
    "        test_features = test_features.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_features)\n",
    "    \n",
    "        train_loss = criterion(outputs, test_features)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    loss = loss / len(dataloader)\n",
    "    \n",
    "    losses.append(loss)\n",
    "    \n",
    "    if epoch % 10 == 0 or epoch - 1 == epochs:\n",
    "        tqdm.write(\"epoch : {}/{}, recon loss = {:.8f}\".format(epoch+1, epochs, loss))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T20:25:44.853196Z",
     "iopub.status.busy": "2024-01-25T20:25:44.852841Z",
     "iopub.status.idle": "2024-01-25T20:25:45.081999Z",
     "shell.execute_reply": "2024-01-25T20:25:45.081117Z",
     "shell.execute_reply.started": "2024-01-25T20:25:44.853169Z"
    }
   },
   "source": [
    "plt.plot(list(range(epochs)), losses)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('L1 Loss')\n",
    "plt.title('Loss history')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T20:40:46.275642Z",
     "iopub.status.busy": "2024-01-25T20:40:46.274946Z",
     "iopub.status.idle": "2024-01-25T20:40:46.289144Z",
     "shell.execute_reply": "2024-01-25T20:40:46.288335Z",
     "shell.execute_reply.started": "2024-01-25T20:40:46.275610Z"
    }
   },
   "source": [
    "# checking the result score\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for X, Y in test_dataset:\n",
    "        X = X[None, :].to(device)\n",
    "        Y = Y[None, :].to(device)\n",
    "            \n",
    "        outputs = model(X)\n",
    "        \n",
    "        l1_val = criterion(outputs, Y)\n",
    "        ssim_val = ssim(outputs, Y, data_range=1, size_average=False)\n",
    "        \n",
    "        print(f'L1 score: {l1_val}')\n",
    "        print(f'SSIM score: {ssim_val[0]}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L1 score tends to 0, and the SSIM score should tend to 1, which means complete similarity with the original image *(in our case, the forecast of the time series)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T20:36:40.577637Z",
     "iopub.status.busy": "2024-01-25T20:36:40.577183Z",
     "iopub.status.idle": "2024-01-25T20:36:40.854543Z",
     "shell.execute_reply": "2024-01-25T20:36:40.853721Z",
     "shell.execute_reply.started": "2024-01-25T20:36:40.577600Z"
    }
   },
   "source": [
    "plt.imshow((1-outputs[0].detach().cpu().numpy()[39]), cmap='gray')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T20:36:41.766028Z",
     "iopub.status.busy": "2024-01-25T20:36:41.765654Z",
     "iopub.status.idle": "2024-01-25T20:36:41.976917Z",
     "shell.execute_reply": "2024-01-25T20:36:41.976026Z",
     "shell.execute_reply.started": "2024-01-25T20:36:41.766002Z"
    }
   },
   "source": [
    "plt.imshow(1 - Y[0].cpu()[39], cmap='gray')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# saving results as a gif-files\n",
    "from tools.generating_time_series import save_gif"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T20:31:46.112045Z",
     "iopub.status.busy": "2024-01-25T20:31:46.111663Z",
     "iopub.status.idle": "2024-01-25T20:31:49.292278Z",
     "shell.execute_reply": "2024-01-25T20:31:49.291529Z",
     "shell.execute_reply.started": "2024-01-25T20:31:46.112020Z"
    }
   },
   "source": [
    "%%capture\n",
    "save_gif(matrices=outputs[0].detach().cpu().numpy(),\n",
    "         name='predict')\n",
    "\n",
    "save_gif(matrices=test[-40:],\n",
    "         name='test')\n",
    "\n",
    "save_gif(matrices=train,\n",
    "         name='train')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# saving models weights\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The final result is below (test data and predict for next 40 frames by 120 previous frames)\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td align=\"center\">\n",
    "        <b>Test<b>\n",
    "      <img src=\"./tools/media/test.gif\">\n",
    "    </td>\n",
    "    <td align=\"center\">\n",
    "        <b>Predict<b>\n",
    "      <img src=\"./tools/media/predict.gif\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Also, you can do the same with 3d or 1d convolution version of the Forecaster model:\n",
    "\n",
    "> Note: if you use 3d convolutions, channels number will be count with using param `channel_growth_rate='power'` in order to make model less heavy. Also, your input_size param should be [H, W]. ForecasterBase3d works only with 2d tensors, which create a 3d tensor with a time period of `in_time_points`.\n",
    "\n",
    "> Note: ForecasterBase1D needs code refactoring wth `in_time_points` and `out_time_point`. Be careful with dimensions to use it for 1d predictions. It will be fixed in future minor versions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "forecaster3d = ForecasterBase(input_size=[65, 65],\n",
    "                              in_time_points=10,\n",
    "                              out_time_points=5,\n",
    "                              n_layers=3,\n",
    "                              normalization='dropout',\n",
    "                              conv_dim=3,\n",
    "                              finish_activation_function=nn.ReLU(inplace=True))\n",
    "forecaster3d"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T06:52:37.649792Z",
     "start_time": "2024-07-13T06:52:37.641744Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4298338,
     "sourceId": 7393613,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
